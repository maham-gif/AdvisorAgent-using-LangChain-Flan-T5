{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuQgqD4lRZdZDedklCXyl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maham-gif/AdvisorAgent-using-LangChain-Flan-T5/blob/main/Complete%20DataAnalyst%20Agent%20With%20User%20Interaction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjAd2LrMc5FT",
        "outputId": "9f46f4f6-4e81-4c80-d548-1c7d92768a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ✅ STEP 1: Install Dependencies\n",
        "!pip install -q openpyxl pandas transformers accelerate sentence-transformers matplotlib\n",
        "\n",
        "# ✅ STEP 2: Import Libraries\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import io\n",
        "\n",
        "# ✅ STEP 3: Upload File\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(io.BytesIO(uploaded[filename]))\n",
        "print(\"✅ File uploaded and read successfully!\\n\")\n",
        "print(df.head(3))\n",
        "\n",
        "# ✅ STEP 4: User Options\n",
        "print(\"🎯 What would you like to do?\")\n",
        "print(\"\"\"\n",
        "Available Tasks:\n",
        "1. clean - Clean dataset (remove duplicates, trim whitespace, drop empty rows)\n",
        "2. fill_missing - Fill missing values intelligently\n",
        "3. analyze - Describe data, generate insights\n",
        "4. generate_rows - Generate new rows based on existing pattern\n",
        "5. delete_rows - Delete specified number of rows\n",
        "6. create_chart - Create a chart\n",
        "7. make_summary - Generate natural language summary of the dataset\n",
        "8. field_meaning - Understand column names via embeddings\n",
        "\"\"\")\n",
        "\n",
        "task = input(\"Enter task: \").strip().lower()\n",
        "\n",
        "# ✅ STEP 5: Load Hugging Face LLM\n",
        "model_id = \"gpt2\"  # Lightweight public model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# ✅ STEP 6: Optional Embeddings Model (RAG help)\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# ✅ STEP 7: Prompt LLM (Safe Prompt)\n",
        "prompt = f\"\"\"\n",
        "You are a professional data analyst working on Excel datasets.\n",
        "This is the top of the dataset:\n",
        "\n",
        "{df.head(5).to_string(index=False)}\n",
        "\n",
        "Your task: {task}.\n",
        "Write clean, safe Python (pandas) code to perform the task.\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_new_tokens=500, temperature=0.7)[0][\"generated_text\"]\n",
        "print(\"\\n🧠 Suggested Code by LLM:\\n\")\n",
        "print(response)\n",
        "\n",
        "# ✅ STEP 8: Interactive Actions Per Task\n",
        "if task == \"clean\":\n",
        "    print(\"⚙️ Cleaning dataset: removing duplicates, empty rows, trimming strings...\")\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.dropna(how='all')\n",
        "    df.columns = df.columns.str.strip()\n",
        "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "    print(\"✅ Dataset cleaned.\")\n",
        "\n",
        "elif task == \"fill_missing\":\n",
        "    method = input(\"Choose fill method (ffill, bfill, mean): \").lower()\n",
        "    if method == \"mean\":\n",
        "        df = df.fillna(df.mean(numeric_only=True))\n",
        "    else:\n",
        "        df = df.fillna(method=method)\n",
        "    print(\"✅ Missing values filled.\")\n",
        "\n",
        "elif task == \"analyze\":\n",
        "    print(\"\\n📊 Summary Statistics:\\n\")\n",
        "    print(df.describe(include='all'))\n",
        "\n",
        "elif task == \"generate_rows\":\n",
        "    num = int(input(\"🔢 How many rows to generate? \"))\n",
        "    sample = df.sample(n=1).to_dict(orient='records')[0]\n",
        "    new_rows = [sample.copy() for _ in range(num)]\n",
        "    df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
        "    print(f\"✅ {num} synthetic rows generated.\")\n",
        "\n",
        "elif task == \"delete_rows\":\n",
        "    print(f\"Current dataset has {len(df)} rows.\")\n",
        "    num = int(input(\"🔻 How many rows would you like to delete from bottom? \"))\n",
        "    df = df.iloc[:-num] if num < len(df) else df.iloc[0:0]\n",
        "    print(f\"✅ {num} rows deleted.\")\n",
        "\n",
        "elif task == \"create_chart\":\n",
        "    print(\"\\n📈 Available columns:\\n\", df.columns.tolist())\n",
        "    x = input(\"Choose X-axis column: \")\n",
        "    y = input(\"Choose Y-axis column: \")\n",
        "    df.plot(x=x, y=y, kind='bar', figsize=(12, 6))\n",
        "    plt.title(f\"{y} vs {x}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "elif task == \"make_summary\":\n",
        "    summary_prompt = f\"\"\"\n",
        "You are a data analyst. Summarize this dataset in 5 lines:\n",
        "\n",
        "{df.head(5).to_string(index=False)}\n",
        "\"\"\"\n",
        "    summary = llm(summary_prompt, max_new_tokens=300)[0][\"generated_text\"]\n",
        "    print(\"\\n📝 Summary:\\n\", summary)\n",
        "\n",
        "elif task == \"field_meaning\":\n",
        "    print(\"\\n🔎 Semantic Understanding of Columns:\")\n",
        "    embeddings = embedder.encode(df.columns)\n",
        "    for i, col in enumerate(df.columns):\n",
        "        print(f\"{col}: ➤ Vector: {embeddings[i][:5]}...\")  # Only showing first 5 dims\n",
        "\n",
        "else:\n",
        "    print(\"❌ Invalid or unrecognized task.\")\n",
        "\n",
        "# ✅ STEP 9: Save Output\n",
        "output_name = \"updated_dataset.xlsx\"\n",
        "df.to_excel(output_name, index=False)\n",
        "files.download(output_name)\n",
        "print(f\"\\n📥 File saved and downloaded: {output_name}\")\n"
      ]
    }
  ]
}
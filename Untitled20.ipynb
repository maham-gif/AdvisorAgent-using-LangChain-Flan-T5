{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFToS6zQZdMge3VbDmt1yA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "999a349d1f124286ad0aea9cff28defc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae2f59d1c88a4bf08dae19c4fb201b96",
              "IPY_MODEL_229d2847e8e04327b46d5c42bcd8c376",
              "IPY_MODEL_f86613ab6f584f2fb252864da176c05e"
            ],
            "layout": "IPY_MODEL_56bb6911a05246f2b8cebae9b28e252a"
          }
        },
        "ae2f59d1c88a4bf08dae19c4fb201b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4487fed05444028c44a0505e70a5bf",
            "placeholder": "​",
            "style": "IPY_MODEL_4e8cb7104360487d8d98ce790af0d6e0",
            "value": "Map: 100%"
          }
        },
        "229d2847e8e04327b46d5c42bcd8c376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06a38fae1dce4f55b889096eeaf1e485",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a69ec39f73d84feb9ebaa80ad5e3b306",
            "value": 2000
          }
        },
        "f86613ab6f584f2fb252864da176c05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50973e0d96894510948812355dd5fbff",
            "placeholder": "​",
            "style": "IPY_MODEL_3cfa24f559b649f68784bad75e4ed201",
            "value": " 2000/2000 [00:03&lt;00:00, 652.90 examples/s]"
          }
        },
        "56bb6911a05246f2b8cebae9b28e252a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a4487fed05444028c44a0505e70a5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8cb7104360487d8d98ce790af0d6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a38fae1dce4f55b889096eeaf1e485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69ec39f73d84feb9ebaa80ad5e3b306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50973e0d96894510948812355dd5fbff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cfa24f559b649f68784bad75e4ed201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea585a7d3e9841ab8e8e095a165c5760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afa318bec34a46c6ae66f0a2ed95aac1",
              "IPY_MODEL_f8c3ef643eb94d4d877f2e412f1822d7",
              "IPY_MODEL_ba1c05b4e05446878c40f5bd86679179"
            ],
            "layout": "IPY_MODEL_ce2b030aa2ec4653a3185db9bb7ee6b3"
          }
        },
        "afa318bec34a46c6ae66f0a2ed95aac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b63f8946f34a9a80e331ef7f936cdb",
            "placeholder": "​",
            "style": "IPY_MODEL_f6446a3b38e74514a4abdd4c05f9a149",
            "value": "Map: 100%"
          }
        },
        "f8c3ef643eb94d4d877f2e412f1822d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f04bc756573401780d4a8d30741a48a",
            "max": 1800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe972da3060e4af6b047187100712d8e",
            "value": 1800
          }
        },
        "ba1c05b4e05446878c40f5bd86679179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b09081dc2e94195baad7b7ae20b56d8",
            "placeholder": "​",
            "style": "IPY_MODEL_5dcf157600eb448c8978235e3c6e7266",
            "value": " 1800/1800 [00:02&lt;00:00, 631.04 examples/s]"
          }
        },
        "ce2b030aa2ec4653a3185db9bb7ee6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b63f8946f34a9a80e331ef7f936cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6446a3b38e74514a4abdd4c05f9a149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f04bc756573401780d4a8d30741a48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe972da3060e4af6b047187100712d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b09081dc2e94195baad7b7ae20b56d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dcf157600eb448c8978235e3c6e7266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db4c0f21b8bb450294414bfc764b5403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c81b5aca716644f091f8833348b33d0d",
              "IPY_MODEL_dd95935e3c394b549c603a8adbbb684c",
              "IPY_MODEL_25fccaddd9ba4fd6bb1e9a58094c0d40"
            ],
            "layout": "IPY_MODEL_40ea626693414ed6a79d743e8ef831c2"
          }
        },
        "c81b5aca716644f091f8833348b33d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_126405e2cc4848b6accb9ce83ebcc349",
            "placeholder": "​",
            "style": "IPY_MODEL_84fd69c77b5f4568877494ddf88fc3a7",
            "value": "Map: 100%"
          }
        },
        "dd95935e3c394b549c603a8adbbb684c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d0fba82d5a4d14abec00d735db4a4a",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39a929d4a1b14f948807e93608e0b307",
            "value": 200
          }
        },
        "25fccaddd9ba4fd6bb1e9a58094c0d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9bf867cedac4206af590e29f2bc531a",
            "placeholder": "​",
            "style": "IPY_MODEL_b492de2ed8ff44d292dc1f9ce89b4a9b",
            "value": " 200/200 [00:00&lt;00:00, 403.49 examples/s]"
          }
        },
        "40ea626693414ed6a79d743e8ef831c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126405e2cc4848b6accb9ce83ebcc349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fd69c77b5f4568877494ddf88fc3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d0fba82d5a4d14abec00d735db4a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a929d4a1b14f948807e93608e0b307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9bf867cedac4206af590e29f2bc531a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b492de2ed8ff44d292dc1f9ce89b4a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maham-gif/AdvisorAgent-using-LangChain-Flan-T5/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade \\\n",
        "  transformers \\\n",
        "  accelerate \\\n",
        "  peft \\\n",
        "  datasets \\\n",
        "  bitsandbytes \\\n",
        "  einops \\\n",
        "  sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp6QznVwJieQ",
        "outputId": "cba7fcee-0e0c-48dd-b3d4-cbbf6abca240"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.1.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y bitsandbytes triton\n",
        "\n",
        "!pip install -q bitsandbytes==0.41.1 triton==2.0.0 sentencepiece==0.1.96 transformers==4.51.0 peft==0.10.0 accelerate==0.29.3 datasets==2.19.1 einops==0.7.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLC-uUgNNU0E",
        "outputId": "0d29fd9e-2158-44f4-d561-f7980f6fab88"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: bitsandbytes 0.47.0\n",
            "Uninstalling bitsandbytes-0.47.0:\n",
            "  Successfully uninstalled bitsandbytes-0.47.0\n",
            "Found existing installation: triton 3.4.0\n",
            "Uninstalling triton-3.4.0:\n",
            "  Successfully uninstalled triton-3.4.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement triton==2.0.0 (from versions: 2.2.0, 2.3.0, 2.3.1, 3.0.0, 3.1.0, 3.2.0, 3.3.0, 3.3.1, 3.4.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for triton==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
        "MAX_ROWS = 2000\n",
        "MAX_SEQ_LEN = 512\n",
        "BATCH_SIZE = 4\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"StephanAkkerman/financial-tweets-crypto\", split=\"train\")\n",
        "df = pd.DataFrame(dataset)\n",
        "df = df.head(MAX_ROWS)\n",
        "print(\"Dataset loaded:\", df.shape)\n",
        "print(df.head(2))\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True,\n",
        "    use_fast=False\n",
        ")\n",
        "\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = PAD_TOKEN\n",
        "if tokenizer.bos_token is None:\n",
        "    tokenizer.add_special_tokens({\"bos_token\": \"<bos>\"})\n",
        "if tokenizer.eos_token is None:\n",
        "    tokenizer.add_special_tokens({\"eos_token\": \"<eos>\"})\n",
        "\n",
        "PAD_TOKEN = tokenizer.pad_token\n",
        "BOS_TOKEN = tokenizer.bos_token\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "print(\"Tokenizer loaded with special tokens:\", {\"pad\": PAD_TOKEN, \"bos\": BOS_TOKEN, \"eos\": EOS_TOKEN})\n",
        "\n",
        "\n",
        "def build_prompt(text):\n",
        "    bos = tokenizer.bos_token or \"<bos>\"\n",
        "    eos = tokenizer.eos_token or \"<eos>\"\n",
        "    return f\"{bos} {text} {eos}\"\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    prompts = [build_prompt(text) for text in batch[\"description\"]]\n",
        "    encodings = tokenizer(\n",
        "        prompts,\n",
        "        max_length=MAX_SEQ_LEN,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    encodings[\"labels\"] = encodings[\"input_ids\"].clone()\n",
        "    return encodings\n",
        "\n",
        "hf_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "\n",
        "tokenized_dataset = hf_dataset.map(\n",
        "    tokenize_batch,\n",
        "    batched=True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    remove_columns=hf_dataset.column_names\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Sample tokenized input_ids shape:\", len(tokenized_dataset[0][\"input_ids\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709,
          "referenced_widgets": [
            "999a349d1f124286ad0aea9cff28defc",
            "ae2f59d1c88a4bf08dae19c4fb201b96",
            "229d2847e8e04327b46d5c42bcd8c376",
            "f86613ab6f584f2fb252864da176c05e",
            "56bb6911a05246f2b8cebae9b28e252a",
            "9a4487fed05444028c44a0505e70a5bf",
            "4e8cb7104360487d8d98ce790af0d6e0",
            "06a38fae1dce4f55b889096eeaf1e485",
            "a69ec39f73d84feb9ebaa80ad5e3b306",
            "50973e0d96894510948812355dd5fbff",
            "3cfa24f559b649f68784bad75e4ed201"
          ]
        },
        "id": "x-bbu15GNfuD",
        "outputId": "380a58e2-db78-43bc-fce1-81d83b0824c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: (2000, 13)\n",
            "                                         image_url  \\\n",
            "0  https://pbs.twimg.com/media/F-7h_aha8AAd-bI.jpg   \n",
            "1  https://pbs.twimg.com/media/F-7nxyVWQAAC7Pc.png   \n",
            "\n",
            "                                     proxy_image_url image_dimensions  \\\n",
            "0  https://images-ext-1.discordapp.net/external/W...      (649, 1200)   \n",
            "1  https://images-ext-1.discordapp.net/external/N...      (1200, 573)   \n",
            "\n",
            "                                       thumbnail_url  \\\n",
            "0  https://pbs.twimg.com/profile_images/154295574...   \n",
            "1  https://pbs.twimg.com/profile_images/164958768...   \n",
            "\n",
            "                                 proxy_thumbnail_url thumbnail_dimensions  \\\n",
            "0  https://images-ext-1.discordapp.net/external/S...             (48, 48)   \n",
            "1  https://images-ext-1.discordapp.net/external/l...             (48, 48)   \n",
            "\n",
            "                          timestamp  \\\n",
            "0  2023-11-14T23:06:39.390000+00:00   \n",
            "1  2023-11-14T23:31:41.017000+00:00   \n",
            "\n",
            "                                         description  \\\n",
            "0  Crazy that $PRIME is going to >$1B market cap ...   \n",
            "1  Crazy part is, a lot of what I have been tradi...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://twitter.com/user/status/17245642086025...   \n",
            "1  https://twitter.com/user/status/17245705594498...   \n",
            "\n",
            "                                         embed_title tweet_type  \\\n",
            "0              Crypto Mikey tweeted about PRIME, AXS      tweet   \n",
            "1  Don't follow Shardi B If You Hate Money tweete...      tweet   \n",
            "\n",
            "                                      financial_info sentiment  \n",
            "0  [{'ticker': '$PRIME', 'exchanges': [], 'price'...   Bullish  \n",
            "1  [{'ticker': '$MATIC', 'exchanges': ['binance',...   Bullish  \n",
            "Tokenizer loaded with special tokens: {'pad': '<|endoftext|>', 'bos': '<bos>', 'eos': '<|im_end|>'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "999a349d1f124286ad0aea9cff28defc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample tokenized input_ids shape: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "MAX_ROWS = 2000\n",
        "MAX_TICKERS = 5\n",
        "BOS_TOKEN = \"<bos>\"\n",
        "EOS_TOKEN = \"<eos>\"\n",
        "\n",
        "\n",
        "df = df.head(MAX_ROWS)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "\n",
        "def slot_financial_info(fin_info_str):\n",
        "    try:\n",
        "        fin_info = ast.literal_eval(fin_info_str)\n",
        "        tickers = [x.get(\"ticker\", \"<NO_TICKER>\") for x in fin_info if isinstance(x, dict)]\n",
        "        if not tickers:\n",
        "            tickers = [\"<NO_TICKER>\"]\n",
        "\n",
        "        return tickers[:MAX_TICKERS] + [\"<NO_TICKER>\"]*(MAX_TICKERS-len(tickers))\n",
        "    except:\n",
        "        return [\"<NO_TICKER>\"]*MAX_TICKERS\n",
        "\n",
        "df[\"fin_slots\"] = df[\"financial_info\"].apply(slot_financial_info)\n",
        "\n",
        "\n",
        "def prepare_prefix_text(slots):\n",
        "    slot_text = \" | \".join(slots)           # slotting separation\n",
        "    return f\"{BOS_TOKEN} {slot_text} {EOS_TOKEN}\"\n",
        "\n",
        "df[\"prefix_input\"] = df[\"fin_slots\"].apply(prepare_prefix_text)\n",
        "\n",
        "\n",
        "print(df[[\"financial_info\", \"fin_slots\", \"prefix_input\", \"sentiment\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeqs-lJIFXlx",
        "outputId": "08480f88-a8c0-4368-adbc-1842fba9d0fd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (2000, 13)\n",
            "                                      financial_info  \\\n",
            "0  [{'ticker': '$PRIME', 'exchanges': [], 'price'...   \n",
            "1  [{'ticker': '$MATIC', 'exchanges': ['binance',...   \n",
            "2  [{'ticker': '$AVAX', 'exchanges': ['kucoin', '...   \n",
            "3  [{'ticker': '$SOL', 'exchanges': ['kucoin', 'b...   \n",
            "4  [{'ticker': '$INJ', 'exchanges': ['binance', '...   \n",
            "\n",
            "                                           fin_slots  \\\n",
            "0  [$PRIME, $AXS, <NO_TICKER>, <NO_TICKER>, <NO_T...   \n",
            "1  [$MATIC, <NO_TICKER>, <NO_TICKER>, <NO_TICKER>...   \n",
            "2  [$AVAX, <NO_TICKER>, <NO_TICKER>, <NO_TICKER>,...   \n",
            "3  [$SOL, <NO_TICKER>, <NO_TICKER>, <NO_TICKER>, ...   \n",
            "4  [$INJ, <NO_TICKER>, <NO_TICKER>, <NO_TICKER>, ...   \n",
            "\n",
            "                                        prefix_input sentiment  \n",
            "0  <bos> $PRIME | $AXS | <NO_TICKER> | <NO_TICKER...   Bullish  \n",
            "1  <bos> $MATIC | <NO_TICKER> | <NO_TICKER> | <NO...   Bullish  \n",
            "2  <bos> $AVAX | <NO_TICKER> | <NO_TICKER> | <NO_...   Bullish  \n",
            "3  <bos> $SOL | <NO_TICKER> | <NO_TICKER> | <NO_T...   Bullish  \n",
            "4  <bos> $INJ | <NO_TICKER> | <NO_TICKER> | <NO_T...   Bullish  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SENTIMENT_PROMPT = \"\"\"\n",
        "Analyze the financial information of the following cryptocurrency tickers and determine the overall sentiment.\n",
        "\n",
        "<items>\n",
        "<item>The overall sentiment for the listed cryptocurrencies (choose one: \"Bullish\", \"Neutral\", or \"Bearish\")</item>\n",
        "<item>A list of all tickers provided in the input</item>\n",
        "<item>A concise one-sentence explanation justifying your sentiment classification</item>\n",
        "</items>\n",
        "\n",
        "<tickers>\n",
        "{tickers}\n",
        "</tickers>\n",
        "\n",
        "<response_format>\n",
        "<think>\n",
        "Provide a brief reasoning sentence explaining your sentiment decision based on the financial data of the tickers.\n",
        "</think>\n",
        "\n",
        "{{\n",
        "  \"sentiment\": \"your sentiment classification\",\n",
        "  \"tickers\": [{tickers_list}]\n",
        "}}\n",
        "</response_format>\n",
        "\"\"\".strip()\n",
        "\n",
        "SENTIMENT_RESPONSE_TEMPLATE = \"\"\"\n",
        "<think>\n",
        "{thoughts}\n",
        "</think>\n",
        "\n",
        "{prediction}\n",
        "\"\"\".strip()\n"
      ],
      "metadata": {
        "id": "hCL30fH7BZgl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "MAX_ROWS = 2000\n",
        "DISPLAY_ROWS = 50\n",
        "COLUMNS = [\"description\", \"financial_info\", \"sentiment\"]\n",
        "\n",
        "hf_ds = load_dataset(\"StephanAkkerman/financial-tweets-crypto\", split=\"train\")\n",
        "df = hf_ds.to_pandas()\n",
        "\n",
        "\n",
        "df.rename(columns={\"text\": \"description\", \"label\": \"sentiment\"}, inplace=True)\n",
        "\n",
        "\n",
        "df = df[COLUMNS].head(MAX_ROWS).copy()\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Loaded dataset in memory:\", len(df), \"rows\\n\")\n",
        "print(\"First\", DISPLAY_ROWS, \"rows:\\n\")\n",
        "print(df.head(DISPLAY_ROWS))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLJFV-foBub2",
        "outputId": "a7ebd0c9-4717-47df-d56f-13801db63a65"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset in memory: 2000 rows\n",
            "\n",
            "First 50 rows:\n",
            "\n",
            "                                          description  \\\n",
            "0   Crazy that $PRIME is going to >$1B market cap ...   \n",
            "1   Crazy part is, a lot of what I have been tradi...   \n",
            "2                      $AVAX\\n\\nStacking on support..   \n",
            "3                                       $SOL\\n\\nLFG!!   \n",
            "4   $INJ - Twitter been super bullish on this one ...   \n",
            "5                       $BONK looks ready to get sent   \n",
            "6   $BTC\\n\\nWhen you zoom out, all good\\n\\nAnd we ...   \n",
            "7                                              $MATIC   \n",
            "8   RT @BigChonis: $BTC - quick video update on #b...   \n",
            "9   25E buy from a $2M wallet \\n\\nFew 10E buys ear...   \n",
            "10  0-56 days now \\n\\nOne day you wake up, and you...   \n",
            "11                                          $gft #gft   \n",
            "12            $SOL getting ready for the move to $60+   \n",
            "13  Now that fake Su Zhu sold his $ATOR bags it lo...   \n",
            "14  I don’t think you realize how big #0X0 will be...   \n",
            "15           Whatever happened to those $HEX cultist?   \n",
            "16  $BONK negative funding.\\n\\nShorts go to horny ...   \n",
            "17  Entered a tight stop scalp short on #BTC, mana...   \n",
            "18  RT @CryptoJelleNL: If #Bitcoin can hold this a...   \n",
            "19  #gas $gas take partial profit from 7% onwards ...   \n",
            "20  When I say $SOL doesn't give a fuck, I mean it...   \n",
            "21  Shorts got bonked\\n\\n> [@Captain_Kole1](https:...   \n",
            "22  Read this once @citadelswap $fort\\n\\n> [@Crypt...   \n",
            "23  Double top visible on 4h n above\\nPositive fun...   \n",
            "24  $FET here is the obstacle he must overcome to ...   \n",
            "25  $LDO is going to turbo send imo.\\n\\nthere's on...   \n",
            "26  Nite killed it with $ator . \\n\\nHe threadoorre...   \n",
            "27  Flip line and confirm $KAVA \\n\\n> [@eliz883](h...   \n",
            "28                    Loaded $WNT here at mid range 🎯   \n",
            "29  Update $ETH \\n\\n> [@eliz883](https://twitter.c...   \n",
            "30  RT @tanoeth: $GMX is going to print me a few $...   \n",
            "31                                 dips is gift $DYDX   \n",
            "32  #Bitcoin Not the worst looking chart.\\n\\nBulls...   \n",
            "33  If #Bitcoin can hold these prices -- we're loo...   \n",
            "34  Pretty sure this is going to break into new AT...   \n",
            "35  When the bull market gets underway, demand for...   \n",
            "36  #Bitcoin is still following the rough expectat...   \n",
            "37  It's still early, but as it stands it looks li...   \n",
            "38  My expectation has been that $ETH/BTC will ret...   \n",
            "39  RT @CryptoNoanGemz: #BRIDGING 👇\\n\\nTo Bridge $...   \n",
            "40  Leverage trading with funds from your web3 wal...   \n",
            "41  2x hit $TVK ...but i think more in next weeks\\...   \n",
            "42  Best trade of the day, how much you made? #gro...   \n",
            "43  RT @CryptoJelleNL: If #Bitcoin can hold this a...   \n",
            "44  RT @CryptoJelleNL: Dips are an inevitable part...   \n",
            "45  RT @CryptoBullet1: $MAV is breaking out 👀 📈\\n\\...   \n",
            "46                       $ETH what a perfection 4% up   \n",
            "47  Of course, the biggest rippers are the ones th...   \n",
            "48                            $SOL\\n\\nBooooooooooooom   \n",
            "49        $FET\\n\\nNailed the local bottom on this one   \n",
            "\n",
            "                                       financial_info sentiment  \n",
            "0   [{'ticker': '$PRIME', 'exchanges': [], 'price'...   Bullish  \n",
            "1   [{'ticker': '$MATIC', 'exchanges': ['binance',...   Bullish  \n",
            "2   [{'ticker': '$AVAX', 'exchanges': ['kucoin', '...   Bullish  \n",
            "3   [{'ticker': '$SOL', 'exchanges': ['kucoin', 'b...   Bullish  \n",
            "4   [{'ticker': '$INJ', 'exchanges': ['binance', '...   Bullish  \n",
            "5   [{'ticker': '$BONK', 'exchanges': [], 'price':...   Neutral  \n",
            "6   [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bullish  \n",
            "7   [{'ticker': '$MATIC', 'exchanges': ['binance',...   Neutral  \n",
            "8   [{'ticker': '$BTC', 'exchanges': ['binance', '...   Neutral  \n",
            "9   [{'ticker': '$PAAL', 'exchanges': [], 'price':...   Bullish  \n",
            "10  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Neutral  \n",
            "11  [{'ticker': '$GFT', 'exchanges': ['binance', '...   Neutral  \n",
            "12  [{'ticker': '$SOL', 'exchanges': ['kucoin', 'b...   Bullish  \n",
            "13  [{'ticker': '$ATOR', 'exchanges': [], 'price':...   Bullish  \n",
            "14  [{'ticker': '$0X0', 'exchanges': [], 'price': ...   Bearish  \n",
            "15  [{'ticker': '$HEX', 'exchanges': [], 'price': ...   Bearish  \n",
            "16  [{'ticker': '$BONK', 'exchanges': [], 'price':...   Bearish  \n",
            "17  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bearish  \n",
            "18  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bullish  \n",
            "19  [{'ticker': '$L', 'exchanges': [], 'price': '6...   Bullish  \n",
            "20  [{'ticker': '$SOL', 'exchanges': ['kucoin', 'b...   Bearish  \n",
            "21  [{'ticker': '$BONK', 'exchanges': [], 'price':...   Bearish  \n",
            "22  [{'ticker': '$FORT', 'exchanges': ['kucoin'], ...   Neutral  \n",
            "23  [{'ticker': '$BONK', 'exchanges': [], 'price':...   Bullish  \n",
            "24  [{'ticker': '$FET', 'exchanges': ['binance', '...   Bullish  \n",
            "25  [{'ticker': '$LDO', 'exchanges': ['kucoin', 'b...   Bullish  \n",
            "26  [{'ticker': '$ATOR', 'exchanges': [], 'price':...   Bearish  \n",
            "27  [{'ticker': '$KAVA', 'exchanges': ['kucoin', '...   Neutral  \n",
            "28  [{'ticker': '$WNT', 'exchanges': [], 'price': ...   Bullish  \n",
            "29  [{'ticker': '$ETH', 'exchanges': ['kucoin', 'b...   Neutral  \n",
            "30  [{'ticker': '$ETH', 'exchanges': ['kucoin', 'b...   Neutral  \n",
            "31  [{'ticker': '$DYDX', 'exchanges': [], 'price':...   Bullish  \n",
            "32  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bearish  \n",
            "33  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bearish  \n",
            "34  [{'ticker': '$INJ', 'exchanges': ['binance', '...   Bullish  \n",
            "35  [{'ticker': '$CRV', 'exchanges': ['binance', '...   Bullish  \n",
            "36  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bullish  \n",
            "37  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bullish  \n",
            "38  [{'ticker': '$ETH', 'exchanges': ['kucoin', 'b...   Bullish  \n",
            "39  [{'ticker': '$ETH', 'exchanges': ['kucoin', 'b...   Neutral  \n",
            "40  [{'ticker': '$GMX', 'exchanges': ['kucoin', 'b...   Neutral  \n",
            "41  [{'ticker': '$TVK', 'exchanges': ['binance', '...   Bullish  \n",
            "42  [{'ticker': '$GROK', 'exchanges': [], 'price':...   Bullish  \n",
            "43  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bullish  \n",
            "44  [{'ticker': '$BTC', 'exchanges': ['binance', '...   Bearish  \n",
            "45  [{'ticker': '$MAV', 'exchanges': ['binance', '...   Neutral  \n",
            "46  [{'ticker': '$ETH', 'exchanges': ['kucoin', 'b...   Bullish  \n",
            "47  [{'ticker': '$AVAX', 'exchanges': ['kucoin', '...   Neutral  \n",
            "48  [{'ticker': '$SOL', 'exchanges': ['kucoin', 'b...   Bullish  \n",
            "49  [{'ticker': '$FET', 'exchanges': ['binance', '...   Bullish  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "\n",
        "MAX_TICKERS = 2\n",
        "\n",
        "TICKER_REGEX = re.compile(r'\\$[A-Za-z0-9_]{1,8}')\n",
        "\n",
        "\n",
        "data = [\n",
        "    {\"description\":\"Crazy $BTC move\", \"financial_info\":\"$BTC up\", \"sentiment\":\"Bullish\"},\n",
        "    {\"description\":\"$ETH dip\", \"financial_info\":\"$ETH down\", \"sentiment\":\"Bearish\"},\n",
        "    {\"description\":\"$SOL breakout\", \"financial_info\":\"$SOL surge\", \"sentiment\":\"Bullish\"}\n",
        "]\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def parse_fin_info(x):\n",
        "    if pd.isna(x) or x is None:\n",
        "        return []\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    if isinstance(x, dict):\n",
        "        return [x]\n",
        "    # fallback: extract tickers\n",
        "    tickers = TICKER_REGEX.findall(str(x))\n",
        "    return [{\"ticker\": t} for t in tickers] if tickers else []\n",
        "\n",
        "def slot_financial_info_list(lst, max_slots=MAX_TICKERS):\n",
        "    out = []\n",
        "    for entry in lst[:max_slots]:\n",
        "        t = entry.get(\"ticker\",\"<NO_TICKER>\")\n",
        "        out.append({\"ticker\":t,\"price\":\"<NO_PRICE>\",\"ta4\":\"<NO_TA4>\",\"ta1\":\"<NO_TA1>\",\"ex\":\"<NO_EX>\"})\n",
        "    while len(out) < max_slots:\n",
        "        out.append({\"ticker\":\"<NO_SLOT>\",\"price\":\"<NO_PRICE>\",\"ta4\":\"<NO_TA4>\",\"ta1\":\"<NO_TA1>\",\"ex\":\"<NO_EX>\"})\n",
        "    return out\n",
        "\n",
        "def financial_slots_to_text(slots):\n",
        "    parts = []\n",
        "    for i, s in enumerate(slots, start=1):\n",
        "        parts.append(f\"[FIN{i}] {s['ticker']} | price:{s['price']} | 4h:{s['ta4']} | 1d:{s['ta1']} | ex:{s['ex']}\")\n",
        "    return \" || \".join(parts)\n",
        "\n",
        "# ---------------- Apply ----------------\n",
        "df[\"_parsed_fin\"] = df[\"financial_info\"].apply(parse_fin_info)\n",
        "df[\"_slots\"] = df[\"_parsed_fin\"].apply(lambda lst: slot_financial_info_list(lst, MAX_TICKERS))\n",
        "df[\"fin_slots_text\"] = df[\"_slots\"].apply(financial_slots_to_text)\n",
        "\n",
        "# ---------------- Display as simple DF ----------------\n",
        "print(df[[\"description\",\"fin_slots_text\",\"sentiment\"]].to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXAwLt_OByYU",
        "outputId": "6cec0ccc-848d-447e-c639-47edcc320832"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    description                                                                                                                                          fin_slots_text sentiment\n",
            "Crazy $BTC move [FIN1] $BTC | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX> || [FIN2] <NO_SLOT> | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX>   Bullish\n",
            "       $ETH dip [FIN1] $ETH | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX> || [FIN2] <NO_SLOT> | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX>   Bearish\n",
            "  $SOL breakout [FIN1] $SOL | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX> || [FIN2] <NO_SLOT> | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX>   Bullish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
        "SAVE_MODEL_DIR = \"Qwen3-0.6B-crypto-sentiment\"\n",
        "\n",
        "# ----------------- Load Tokenizer (Slow) -----------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True,\n",
        "    use_fast=False\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else \"<pad>\"\n",
        "if tokenizer.bos_token is None:\n",
        "    tokenizer.add_special_tokens({\"bos_token\": \"<bos>\"})\n",
        "if tokenizer.eos_token is None:\n",
        "    tokenizer.add_special_tokens({\"eos_token\": \"<eos>\"})\n",
        "\n",
        "\n",
        "PAD_TOKEN = tokenizer.pad_token\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "BOS_TOKEN = tokenizer.bos_token\n",
        "\n",
        "print(\"Tokens:\", {\"pad\": PAD_TOKEN, \"eos\": EOS_TOKEN, \"bos\": BOS_TOKEN})\n",
        "print(\"Tokenizer vocab size:\", len(tokenizer))\n",
        "\n",
        "\n",
        "if not os.path.exists(SAVE_MODEL_DIR):\n",
        "    os.makedirs(SAVE_MODEL_DIR)\n",
        "\n",
        "tokenizer.save_pretrained(SAVE_MODEL_DIR)\n",
        "print(f\"Tokenizer saved to {SAVE_MODEL_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozOzU46kBz46",
        "outputId": "b20e230c-d635-49a9-f2ec-9650568495f9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: {'pad': '<|endoftext|>', 'eos': '<|im_end|>', 'bos': '<bos>'}\n",
            "Tokenizer vocab size: 151670\n",
            "Tokenizer saved to Qwen3-0.6B-crypto-sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PROMPT_TEMPLATE = (\n",
        "    \"{bos} FINANCIAL_SLOTS: {fin}\\nTWEET: {tweet}\\nRESPONSE_FORMAT:\\n\"\n",
        "    '{{\"sentiment\":\"<Bullish|Neutral|Bearish>\"}}\\nAnswer:'\n",
        ")\n",
        "\n",
        "def clean_tweet_text(s: str) -> str:\n",
        "    if pd.isna(s): return \"\"\n",
        "    s = str(s)\n",
        "\n",
        "    s = re.sub(r'https?://\\S+', '', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s\n",
        "\n",
        "def build_prompt_and_target(fin_text: str, tweet_text: str, sentiment: str):\n",
        "    \"\"\"\n",
        "    Build prompt string (no extra special tokens) and a short target string (the sentiment).\n",
        "    We'll always include bos token at the front (tokenizer.bos_token).\n",
        "    \"\"\"\n",
        "    tweet_clean = clean_tweet_text(tweet_text)\n",
        "    bos = BOS_TOKEN or \"\"\n",
        "    prompt = PROMPT_TEMPLATE.format(bos=bos, fin=fin_text, tweet=tweet_clean)\n",
        "\n",
        "    target = \" \" + sentiment.strip() + (tokenizer.eos_token or \"\")\n",
        "    return prompt, target\n",
        "\n",
        "def smart_tokenize_example(prompt: str, target: str, max_seq_len=MAX_SEQ_LEN):\n",
        "    \"\"\"\n",
        "    Tokenize prompt and target separately, then create input_ids and labels with prompt masked (-100).\n",
        "    Truncation strategy: keep TAIL of prompt when trimming so tickers near end are preserved.\n",
        "    \"\"\"\n",
        "    enc_prompt = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
        "    enc_target = tokenizer(target, add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "\n",
        "    if len(enc_target) > max_seq_len - 2:\n",
        "\n",
        "        enc_target = enc_target[-(max_seq_len//4):]\n",
        "\n",
        "    total_len = len(enc_prompt) + len(enc_target)\n",
        "    if total_len > max_seq_len:\n",
        "\n",
        "        allowed_prompt_len = max_seq_len - len(enc_target)\n",
        "\n",
        "        enc_prompt = enc_prompt[-allowed_prompt_len:]\n",
        "\n",
        "    input_ids = enc_prompt + enc_target\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "\n",
        "    labels = [-100] * len(enc_prompt) + enc_target\n",
        "\n",
        "\n",
        "    pad_len = max_seq_len - len(input_ids)\n",
        "    if pad_len > 0:\n",
        "        input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n",
        "        attention_mask = attention_mask + [0] * pad_len\n",
        "        labels = labels + [-100] * pad_len\n",
        "\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
        "\n",
        "# quick check\n",
        "p, t = build_prompt_and_target(df.loc[0,\"fin_slots_text\"], df.loc[0,\"description\"], df.loc[0,\"sentiment\"])\n",
        "print(\"Prompt sample:\", p[:300].replace(\"\\n\",\"\\\\n\"))\n",
        "print(\"Target sample:\", t)\n",
        "print(\"Tokenized lengths:\", {k: len(v) for k,v in smart_tokenize_example(p,t).items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTIX5N9zB3L6",
        "outputId": "d977b104-733d-4740-ebee-dda6424681bd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt sample: <bos> FINANCIAL_SLOTS: [FIN1] $BTC | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX> || [FIN2] <NO_SLOT> | price:<NO_PRICE> | 4h:<NO_TA4> | 1d:<NO_TA1> | ex:<NO_EX>\\nTWEET: Crazy $BTC move\\nRESPONSE_FORMAT:\\n{\"sentiment\":\"<Bullish|Neutral|Bearish>\"}\\nAnswer:\n",
            "Target sample:  Bullish<|im_end|>\n",
            "Tokenized lengths: {'input_ids': 512, 'attention_mask': 512, 'labels': 512}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LoRALinear(nn.Module):\n",
        "    def __init__(self, orig_linear: nn.Linear, r=8, alpha=32, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.orig_linear = orig_linear\n",
        "        self.r = r\n",
        "        self.alpha = alpha\n",
        "        self.scaling = alpha / r\n",
        "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
        "\n",
        "        self.A = nn.Parameter(torch.randn(r, orig_linear.in_features) * 0.01)\n",
        "        self.B = nn.Parameter(torch.randn(orig_linear.out_features, r) * 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lora_out = (self.B @ (self.A @ x.T)).T\n",
        "        return self.orig_linear(x) + self.dropout(lora_out * self.scaling)\n",
        "\n",
        "def apply_lora(model: nn.Module, r=8, alpha=32, dropout=0.1, target_modules=None):\n",
        "    if target_modules is None:\n",
        "        target_modules = [\"q_proj\", \"v_proj\"]\n",
        "\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Linear) and any(t in name for t in target_modules):\n",
        "            setattr(model, name, LoRALinear(module, r=r, alpha=alpha, dropout=dropout))\n",
        "        else:\n",
        "            apply_lora(module, r=r, alpha=alpha, dropout=dropout, target_modules=target_modules)\n",
        "    return model\n",
        "\n",
        "def freeze_model_except_lora(model: nn.Module):\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"A\" in name or \"B\" in name:\n",
        "            param.requires_grad = True\n",
        "        else:\n",
        "            param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "9aywqfyJB95b"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "MAX_ROWS = 2000\n",
        "COLUMNS = [\"description\", \"financial_info\", \"sentiment\"]\n",
        "\n",
        "hf_ds = load_dataset(\"StephanAkkerman/financial-tweets-crypto\", split=\"train\")\n",
        "df = hf_ds.to_pandas()\n",
        "df.rename(columns={\"text\": \"description\", \"label\": \"sentiment\"}, inplace=True)\n",
        "df = df[COLUMNS].head(MAX_ROWS).copy()\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Dataset loaded:\", len(df), \"rows\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtyUGNN7CBOH",
        "outputId": "b3c25b4b-e4ab-44c4-c8df-889ae8faeb2f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: 2000 rows\n",
            "                                         description  \\\n",
            "0  Crazy that $PRIME is going to >$1B market cap ...   \n",
            "1  Crazy part is, a lot of what I have been tradi...   \n",
            "2                     $AVAX\\n\\nStacking on support..   \n",
            "3                                      $SOL\\n\\nLFG!!   \n",
            "4  $INJ - Twitter been super bullish on this one ...   \n",
            "\n",
            "                                      financial_info sentiment  \n",
            "0  [{'ticker': '$PRIME', 'exchanges': [], 'price'...   Bullish  \n",
            "1  [{'ticker': '$MATIC', 'exchanges': ['binance',...   Bullish  \n",
            "2  [{'ticker': '$AVAX', 'exchanges': ['kucoin', '...   Bullish  \n",
            "3  [{'ticker': '$SOL', 'exchanges': ['kucoin', 'b...   Bullish  \n",
            "4  [{'ticker': '$INJ', 'exchanges': ['binance', '...   Bullish  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import torch\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "\n",
        "    target_modules=[\"q_proj\", \"v_proj\"]\n",
        ")\n",
        "\n",
        "# Apply LoRA\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Move to CUDA\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "print(f\"LoRA model loaded and moved to {device}. Ready for fine-tuning!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuDYnV-iIf-6",
        "outputId": "97097fbd-e600-414e-bf37-35f94b61ee89"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA model loaded and moved to cuda. Ready for fine-tuning!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bitsandbytes accelerate peft transformers datasets\n"
      ],
      "metadata": {
        "id": "TisJdkraKqeh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "df[\"text\"] = df[\"description\"].astype(str) + \" \" + df[\"financial_info\"].astype(str)\n",
        "dataset = Dataset.from_pandas(df[[\"text\", \"sentiment\"]])\n",
        "\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "# Tokenize\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\", \"sentiment\"])\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Move model to CUDA\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qwen-lora-finetuned\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=3e-4,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch\",\n",
        "    report_to=\"none\"  # avoid W&B\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"./qwen-lora-finetuned\")\n",
        "print(\"LoRA fine-tuned model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "ea585a7d3e9841ab8e8e095a165c5760",
            "afa318bec34a46c6ae66f0a2ed95aac1",
            "f8c3ef643eb94d4d877f2e412f1822d7",
            "ba1c05b4e05446878c40f5bd86679179",
            "ce2b030aa2ec4653a3185db9bb7ee6b3",
            "c7b63f8946f34a9a80e331ef7f936cdb",
            "f6446a3b38e74514a4abdd4c05f9a149",
            "5f04bc756573401780d4a8d30741a48a",
            "fe972da3060e4af6b047187100712d8e",
            "1b09081dc2e94195baad7b7ae20b56d8",
            "5dcf157600eb448c8978235e3c6e7266",
            "db4c0f21b8bb450294414bfc764b5403",
            "c81b5aca716644f091f8833348b33d0d",
            "dd95935e3c394b549c603a8adbbb684c",
            "25fccaddd9ba4fd6bb1e9a58094c0d40",
            "40ea626693414ed6a79d743e8ef831c2",
            "126405e2cc4848b6accb9ce83ebcc349",
            "84fd69c77b5f4568877494ddf88fc3a7",
            "10d0fba82d5a4d14abec00d735db4a4a",
            "39a929d4a1b14f948807e93608e0b307",
            "f9bf867cedac4206af590e29f2bc531a",
            "b492de2ed8ff44d292dc1f9ce89b4a9b"
          ]
        },
        "id": "roWbtqCIM1H6",
        "outputId": "ec6a95b1-3017-4bc9-afd8-29ae7770712c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea585a7d3e9841ab8e8e095a165c5760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db4c0f21b8bb450294414bfc764b5403"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3021197422.py:89: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='339' max='339' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [339/339 17:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.545300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.274500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.218900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.184400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.146400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.114500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA fine-tuned model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BASE_MODEL = \"Qwen/Qwen3-0.6B\"\n",
        "LORA_PATH = \"./qwen-lora-finetuned\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Load LoRA weights\n",
        "model = PeftModel.from_pretrained(base_model, LORA_PATH)\n",
        "model.eval()\n",
        "\n",
        "# Pipeline without device argument\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "sample_text = \"Ethereum is experiencing high volatility today.\"\n",
        "\n",
        "# Generate text with truncation\n",
        "output = pipe(\n",
        "    sample_text,\n",
        "    max_new_tokens=100,\n",
        "    truncation=True,\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "\n",
        "generated_text = output[0][\"generated_text\"]\n",
        "print(\"Generated string:\\n\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gTv5FRwT3u5",
        "outputId": "68947b53-5bb3-4361-e110-0adc9f71c558"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated string:\n",
            " Ethereum is experiencing high volatility today. The 40k ETH is still under attack.\n",
            "\n",
            "> [@CryptoNoan](https://twitter.com/CryptoNoan):\n",
            "> #Bitcoin is in a bear market. [{'ticker': '$BTC', 'exchanges': ['binance', 'kucoin'], 'price': None, 'percentage_change': None, '4h_ta_result': 'NEUTRAL', '4h_ta_details': '10 buy, 10 hold, 6 sell', '1d_ta_result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "chat_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=100,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "\n",
        "CHATBOT_PROMPT = (\n",
        "    \"You are a financial sentiment assistant. \"\n",
        "    \"Given the financial information: {fin_text} \"\n",
        "    \"and the tweet: {tweet_text} \"\n",
        "    \"Provide a concise, human-readable response explaining the sentiment and reasoning:\"\n",
        ")\n",
        "\n",
        "def chat_response(fin_text, tweet_text):\n",
        "    prompt = CHATBOT_PROMPT.format(fin_text=fin_text, tweet_text=tweet_text)\n",
        "    output = chat_pipe(prompt)[0]['generated_text']\n",
        "    response = output[len(prompt):].strip()  # remove prompt part\n",
        "    return response\n",
        "\n",
        "for i in range(3):\n",
        "    fin_text = str(df.loc[i, \"financial_info\"])      # use existing column\n",
        "    tweet_text = str(df.loc[i, \"description\"])      # use existing column\n",
        "    response = chat_response(fin_text, tweet_text)\n",
        "    print(f\"Sample {i+1} Chatbot Response:\\n{response}\\n{'-'*60}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDW0DQGZZwwa",
        "outputId": "33a93301-4424-4b13-e66e-d122fbf648f1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 Chatbot Response:\n",
            "[{'ticker': '$PRIME', 'exchanges': [], 'price': '5.77', 'percentage_change': '+12.49%', '4h_ta_result': 'STRONG_BUY', '4h_ta_details': '17 buy, 8 hold, 1 sell', '1d_ta_result': 'STRONG_BUY', '1d_ta_details': '16 buy, 9 hold, 1 sell'}] [{'ticker': '$AX\n",
            "------------------------------------------------------------\n",
            "Sample 2 Chatbot Response:\n",
            "[{'ticker': '$MATIC', 'exchanges': ['binance', 'kucoin'], 'price': '0.922456', 'percentage_change': '+3.07%', '4h_ta_result': 'STRONG_BUY', '4h_ta_details': '17 buy, 8 hold, 1 sell', '1d_ta_result': 'STRONG_BUY', '1d_ta_details': '16 buy, 9 hold,\n",
            "------------------------------------------------------------\n",
            "Sample 3 Chatbot Response:\n",
            "[{'ticker': '$AVAX', 'exchanges': ['kucoin', 'binance'], 'price': '17.21', 'percentage_change': '+5.26%', '4h_ta_result': 'BUY', '4h_ta_details': '15 buy, 8 hold, 3 sell', '1d_ta_result': 'BUY', '1d_ta_details': '15 buy, 9 hold, 2 sell'}] [{'ticker': '$\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from peft import PeftModel\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BASE_MODEL = \"Qwen/Qwen3-0.6B\"\n",
        "LORA_PATH = \"./qwen-lora-finetuned\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(base_model, LORA_PATH)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "\n",
        "def chatbot_sentiment(fin_text, tweet_text):\n",
        "    prompt = f\"Financial info: {fin_text}\\nTweet: {tweet_text}\\nSentiment only (Bullish, Neutral, Bearish):\"\n",
        "\n",
        "    output = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=20,\n",
        "        truncation=True,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    # Extract only text after 'Sentiment only:' and remove any extra symbols or brackets\n",
        "    text = output[0][\"generated_text\"]\n",
        "    if \"Sentiment only:\" in text:\n",
        "        text = text.split(\"Sentiment only:\")[-1].strip()\n",
        "\n",
        "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "\n",
        "    text = text.capitalize()\n",
        "\n",
        "    return text\n",
        "\n",
        "samples = df.head(3)\n",
        "\n",
        "for i, row in samples.iterrows():\n",
        "    fin_text = row[\"financial_info\"]\n",
        "    tweet_text = row[\"description\"]\n",
        "\n",
        "    sentiment = chatbot_sentiment(fin_text, tweet_text)\n",
        "\n",
        "    print(f\"Sample {i+1} Chatbot Sentiment: {sentiment}\")\n",
        "    print(\"---------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPVHRnzmappw",
        "outputId": "2a141201-c625-4cae-a01b-3c7ea773e5c7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 Chatbot Sentiment: Financial info ticker prime exchanges  price  percentagechange  htaresult strongbuy htadetails  buy  hold  sell dtaresult strongbuy dtadetails  buy  hold  sell ticker axs exchanges kucoin binance price  percentagechange  htaresult sell htadetails  buy  hold  sell dtaresult buy dtadetails  buy  hold  sell\n",
            "tweet crazy that prime is going to b market cap at the next cycle top as the  axs of this cycle and you still dont own any anon \n",
            "\n",
            " exit or bust bitch\n",
            "sentiment only bullish neutral bearish ticker axs exchanges kucoin binance \n",
            "---------------------------------------------------\n",
            "Sample 2 Chatbot Sentiment: Financial info ticker matic exchanges binance kucoin price  percentagechange  htaresult strongbuy htadetails  buy  hold  sell dtaresult strongbuy dtadetails  buy  hold  sell\n",
            "tweet crazy part is a lot of what i have been trading is still up\n",
            "\n",
            "matic\n",
            "sentiment only bullish neutral bearish ticker matic exchanges binance kucoin \n",
            "---------------------------------------------------\n",
            "Sample 3 Chatbot Sentiment: Financial info ticker avax exchanges kucoin binance price  percentagechange  htaresult buy htadetails  buy  hold  sell dtaresult buy dtadetails  buy  hold  sell\n",
            "tweet avax\n",
            "\n",
            "stacking on support\n",
            "sentiment only bullish neutral bearish ticker avax exchanges kucoin binance \n",
            "---------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}